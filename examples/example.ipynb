{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Lane Finding Project\n",
    "\n",
    "The goals / steps of this project are the following:\n",
    "\n",
    "* Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.\n",
    "* Apply a distortion correction to raw images.\n",
    "* Use color transforms, gradients, etc., to create a thresholded binary image.\n",
    "* Apply a perspective transform to rectify binary image (\"birds-eye view\").\n",
    "* Detect lane pixels and fit to find the lane boundary.\n",
    "* Determine the curvature of the lane and vehicle position with respect to center.\n",
    "* Warp the detected lane boundaries back onto the original image.\n",
    "* Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position.\n",
    "\n",
    "---\n",
    "## First, I'll compute the camera calibration using chessboard images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_undistort(img, objpoints, imgpoints):\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints,\\\n",
    "                                                      imgpoints, img.shape[1:], None, None)\n",
    "    undist = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    return undist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-0dd11826bf64>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#%matplotlib qt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "#%matplotlib qt\n",
    "%matplotlib inline\n",
    "\n",
    "# prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "objp = np.zeros((6*9,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:9,0:6].T.reshape(-1,2)\n",
    "\n",
    "# Arrays to store object points and image points from all the images.\n",
    "objpoints = [] # 3d points in real world space\n",
    "imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "# Make a list of calibration images\n",
    "images = glob.glob('../camera_cal/calibration*.jpg')\n",
    "#images = glob.glob('../test_images/test1.jpg')\n",
    "\n",
    "\n",
    "# Step through the list and search for chessboard corners\n",
    "for fname in images:\n",
    "    img = cv2.imread(fname)\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    nx = 9\n",
    "    ny = 6\n",
    "\n",
    "    # Find the chessboard corners\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (9,6),None)\n",
    "\n",
    "    # If found, add object points, image points\n",
    "    if ret == True:\n",
    "        objpoints.append(objp)\n",
    "        imgpoints.append(corners)\n",
    "\n",
    "        # Undistort using mtx and dist\n",
    "        undist = cal_undistort(img, objpoints, imgpoints)\n",
    "        \n",
    "        \n",
    "        offset = 100 # offset for dst points\n",
    "        img_size = (gray.shape[1], gray.shape[0])\n",
    "        \n",
    "        src = np.float32([corners[0], corners[nx-1], corners[-1], corners[-nx]])\n",
    "        dst = np.float32([[offset, offset], [img_size[0]-offset, offset],\\\n",
    "                         [img_size[0]-offset, img_size[1]-offset],\\\n",
    "                         [offset, img_size[1]-offset]])\n",
    "        M = cv2.getPerspectiveTransform(src, dst)\n",
    "        \n",
    "        warped = cv2.warpPerspective(undist, M, img_size)\n",
    "        \n",
    "        # Draw and display the corners\n",
    "        img = cv2.drawChessboardCorners(img, (nx,ny), corners, ret)\n",
    "        #cv2.imshow('img',img)\n",
    "        #plt.imshow(img)\n",
    "        #cv2.waitKey(500) \n",
    "        \n",
    "#cv2.destroyAllWindows()\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24,9))\n",
    "f.tight_layout()\n",
    "ax1.imshow(img)\n",
    "ax1.set_title('Original Image', fontsize=50)\n",
    "ax2.imshow(warped)\n",
    "ax2.set_title('Undistorted Imgae', fontsize=50)\n",
    "plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "source": [
    "## 2. Describe how (and identify where in your code) you used color transforms, gradients or other methods to create a thresholded binary image. Provide an example of a binary image result."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mag_select(img, sobel_kernel=3, mag_thresh=(0,255)):\n",
    "    # 1) Convert to grayscale\n",
    "    gray_test_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    # 2) Take the gradient in x and y separately\n",
    "    sobelx = cv2.Sobel(gray_test_img, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(gray_test_img, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    \n",
    "    # 3) Calculate the magnitude\n",
    "    abs_sobelxy = np.sqrt(np.square(sobelx)+np.square(sobely))\n",
    "    \n",
    "    # 4) Scale to 8-bit (0-255) and convert to type = np.uint8\n",
    "    scaled_sobel = np.uint8(255*abs_sobelxy/np.max(abs_sobelxy))\n",
    "    \n",
    "    # 5) Create a binary mask where mag thresholds are met\n",
    "    thresh_min = mag_thresh[0]\n",
    "    thresh_max = mag_thresh[1]\n",
    "    \n",
    "    binary_output = np.zeros_like(scaled_sobel)\n",
    "    binary_output[(scaled_sobel >= thresh_min) & (scaled_sobel <= thresh_max)] = 1\n",
    "    \n",
    "    return binary_output\n",
    "\n",
    "def s_select(img, s_thresh=(0,255)):\n",
    "    #1) Convert to HLS color space\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    \n",
    "    #2) Apply a threshold to the S channel\n",
    "    S = hls[:,:,2]\n",
    "    \n",
    "    #3) Return a binary image of threshold result\n",
    "    binary_output = np.zeros_like(S)\n",
    "    binary_output[(S > s_thresh[0]) & (S <= s_thresh[1])] = 1\n",
    "    \n",
    "    return binary_output\n",
    "\n",
    "def h_select(img, h_thresh=(0,255)):\n",
    "    #1) Convert to HLS color space\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    \n",
    "    #2) Apply a threshold to the H channel\n",
    "    H = hls[:,:,0]\n",
    "    \n",
    "    #3) Return a binary image of threshold result\n",
    "    binary_output = np.zeros_like(H)\n",
    "    binary_output[(H > h_thresh[0]) & (H <= h_thresh[1])] = 1\n",
    "    \n",
    "    return binary_output\n",
    "\n",
    "def threshold_pipeline(img, h_thresh=(18,100), s_thresh=(90,255),\\\n",
    "                      mag_thresh=(20,100)):\n",
    "    # Magnitude \n",
    "    mag_binary = mag_select(img, sobel_kernel=3, mag_thresh=(20,100))\n",
    "    print('mag size:{}'.format(mag_binary.shape))\n",
    "    \n",
    "    # Saturation\n",
    "    s_binary = s_select(img, s_thresh=(80,255))\n",
    "    print('s size:{}'.format(s_binary.shape))\n",
    "        \n",
    "    # Hue\n",
    "    h_binary = h_select(img, h_thresh=(20,100))\n",
    "    print('h size:{}'.format(h_binary.shape))\n",
    "        \n",
    "    # Stack each channel\n",
    "    result = np.dstack((np.zeros_like(mag_binary), mag_binary, s_binary, h_binary))*255\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'cv2' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-ba0241576114>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtest_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../test_images/test2.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0ms_binary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms_select\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms_thresh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m80\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mh_binary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh_select\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_thresh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m18\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-7f8bc2adf1d8>\u001b[0m in \u001b[0;36ms_select\u001b[0;34m(img, s_thresh)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0ms_select\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms_thresh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;31m#1) Convert to HLS color space\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mhls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_RGB2HLS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;31m#2) Apply a threshold to the S channel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cv2' is not defined"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "test_img = np.array(Image.open('../test_images/test2.jpg'))\n",
    "\n",
    "s_binary = s_select(test_img, s_thresh=(80, 255))\n",
    "\n",
    "h_binary = h_select(test_img, h_thresh=(18,100))\n",
    "\n",
    "mag_binary = mag_select(test_img, sobel_kernel=3, mag_thresh=(20, 100))\n",
    "\n",
    "combined = np.zeros_like(test_img)\n",
    "combined = threshold_pipeline(test_img)\n",
    "\n",
    "print('combined size:{}'.format(combined.shape))\n",
    "\n",
    "f1, [(ax11, ax12), (ax21, ax22), (ax31, ax32)] = plt.subplots(3, 2, figsize=(24, 9))\n",
    "f1.tight_layout()\n",
    "\n",
    "ax11.imshow(test_img)\n",
    "ax11.set_title('Original Test Image', fontsize=30)\n",
    "\n",
    "ax12.imshow(mag_binary, cmap='gray')\n",
    "ax12.set_title('Thresholded Mag', fontsize=30)\n",
    "\n",
    "ax21.imshow(s_binary, cmap='gray')\n",
    "ax21.set_title('Thresholded S', fontsize=30)\n",
    "\n",
    "ax22.imshow(h_binary, cmap='gray')\n",
    "ax22.set_title('Thresholded H', fontsize=30)\n",
    "\n",
    "ax31.imshow(combined, cmap='gray')\n",
    "ax31.set_title('Thresholded Combined', fontsize=30)\n",
    "\n",
    "plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0., \\\n",
    "                    wspace=0., hspace=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit ('base': conda)",
   "metadata": {
    "interpreter": {
     "hash": "474ae19e00afb86894a89e42c1d098be1678125e01a71fba7ee27dc55676f4fd"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}